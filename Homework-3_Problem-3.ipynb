{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bdc63f-205d-48d0-a129-22c2c884a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries for numpy, plot and pandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4e8aba-5ff6-4c1c-8a01-cc38fab57f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing breast cancer dataset\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0618f9f-e732-42a6-9be0-efeb09d89706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the input variables into a matrix\n",
    "\n",
    "breast_data = breast.data\n",
    "breast_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be37cdb8-3a37-42dd-82c1-206857e933b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the input variables matrix into a 2D panda array\n",
    "\n",
    "breast_input = pd.DataFrame(breast_data)\n",
    "breast_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4347e482-367e-4306-81ec-c455b36d81f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the outputs into a matrix\n",
    "\n",
    "breast_labels = breast.target\n",
    "breast_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8623a405-aee7-465a-85b9-c101489d0a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c103d0f-2250-40cc-bc94-5d2d139f9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the output row matrix into a column\n",
    "\n",
    "labels = np.reshape(breast_labels,(569,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b1e24f-0461-45f5-a7ba-73a281de48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating the input variables and outputs into the same 2D array to create the final dataset\n",
    "\n",
    "final_breast_data = np.concatenate([breast_data,labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3832ce30-6839-46df-87f8-f4b5b34b6c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_breast_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f330ba-ea51-439c-aff7-a38778c56430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the feature names for the input variables\n",
    "\n",
    "breast_dataset = pd.DataFrame(final_breast_data)\n",
    "features = breast.feature_names\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a07bbb11-91ed-48a3-b707-7fd4f618eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labels = np.append(features,'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0bc3257-3816-45e4-b2a7-7006cdd01620",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset.columns = features_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4118080-ddc2-4422-b005-eae1df1551c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890    0.0  \n",
       "1                  0.1860          0.2750                  0.08902    0.0  \n",
       "2                  0.2430          0.3613                  0.08758    0.0  \n",
       "3                  0.2575          0.6638                  0.17300    0.0  \n",
       "4                  0.1625          0.2364                  0.07678    0.0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115    0.0  \n",
       "565                0.1628          0.2572                  0.06637    0.0  \n",
       "566                0.1418          0.2218                  0.07820    0.0  \n",
       "567                0.2650          0.4087                  0.12400    0.0  \n",
       "568                0.0000          0.2871                  0.07039    1.0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc7c2dc-bd69-4035-827d-b10e60026d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset['label'].replace(0, 'Benign',inplace=True)\n",
    "breast_dataset['label'].replace(1, 'Malignant',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5ebc29c-aff8-49c5-a22a-5d418354de2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension      label  \n",
       "0                  0.2654          0.4601                  0.11890     Benign  \n",
       "1                  0.1860          0.2750                  0.08902     Benign  \n",
       "2                  0.2430          0.3613                  0.08758     Benign  \n",
       "3                  0.2575          0.6638                  0.17300     Benign  \n",
       "4                  0.1625          0.2364                  0.07678     Benign  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115     Benign  \n",
       "565                0.1628          0.2572                  0.06637     Benign  \n",
       "566                0.1418          0.2218                  0.07820     Benign  \n",
       "567                0.2650          0.4087                  0.12400     Benign  \n",
       "568                0.0000          0.2871                  0.07039  Malignant  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef4afa4-822c-4e63-8809-5ba593c907bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing standard scalar and standarding the input values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separating out the features\n",
    "x = breast_dataset.loc[:, features].values\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "501de8af-4c8d-4eab-80b8-58a08ab4ed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123167</td>\n",
       "      <td>3.633731</td>\n",
       "      <td>-1.195113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529292</td>\n",
       "      <td>1.118264</td>\n",
       "      <td>0.621778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232790</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459486</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356031</td>\n",
       "      <td>-0.033742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2         3         4\n",
       "0     9.192837   1.948583 -1.123167  3.633731 -1.195113\n",
       "1     2.387802  -3.768172 -0.529292  1.118264  0.621778\n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177087\n",
       "3     7.122953  10.275589 -3.232790  0.152547 -2.960877\n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546748\n",
       "..         ...        ...       ...       ...       ...\n",
       "564   6.439315  -3.576817  2.459486  1.177314 -0.074824\n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510721\n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809992\n",
       "567  10.374794   1.672010 -1.877029 -2.356031 -0.033742\n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184708\n",
       "\n",
       "[569 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalComponents = pd.DataFrame(principalComponents)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bad2d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the principal components as the input variables\n",
    "\n",
    "X = principalComponents.iloc[:, [0,1,2,3,4]].values\n",
    "Y = breast_dataset.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30468f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "#splitting the dataset into 80% and 20% split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daa28858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing naive bays and building the classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee8adc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the classifier on the test data\n",
    "\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "278e7a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9210526315789473\n",
      "Precision: 0.9\n",
      "Recall: 0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "#importing and printing accuracy, precision and recall of the classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "pos_label=['Benign', 'Malignant']\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, pos_label= \"Malignant\"))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, pos_label= \"Malignant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5f00b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123166</td>\n",
       "      <td>3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>1.411428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529293</td>\n",
       "      <td>1.118263</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.028651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177087</td>\n",
       "      <td>0.541457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232790</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960879</td>\n",
       "      <td>3.053426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546748</td>\n",
       "      <td>-1.226496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459487</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074825</td>\n",
       "      <td>-2.375189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510723</td>\n",
       "      <td>-0.246709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809991</td>\n",
       "      <td>-0.534450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356032</td>\n",
       "      <td>-0.033741</td>\n",
       "      <td>0.567933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184704</td>\n",
       "      <td>1.617843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2         3         4         5\n",
       "0     9.192837   1.948583 -1.123166  3.633731 -1.195110  1.411428\n",
       "1     2.387802  -3.768172 -0.529293  1.118263  0.621775  0.028651\n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177087  0.541457\n",
       "3     7.122953  10.275589 -3.232790  0.152547 -2.960879  3.053426\n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546748 -1.226496\n",
       "..         ...        ...       ...       ...       ...       ...\n",
       "564   6.439315  -3.576817  2.459487  1.177314 -0.074825 -2.375189\n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510723 -0.246709\n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809991 -0.534450\n",
       "567  10.374794   1.672010 -1.877029 -2.356032 -0.033741  0.567933\n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184704  1.617843\n",
       "\n",
       "[569 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=6)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalComponents = pd.DataFrame(principalComponents)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9b690c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the principal components as the input variables\n",
    "\n",
    "X = principalComponents.iloc[:, [0,1,2,3,4,5]].values\n",
    "Y = breast_dataset.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a2bc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "#splitting the dataset into 80% and 20% split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "622e2d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing naive bays and building the classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "550c9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the classifier on the test data\n",
    "\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2767ccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9210526315789473\n",
      "Precision: 0.9117647058823529\n",
      "Recall: 0.9538461538461539\n"
     ]
    }
   ],
   "source": [
    "#importing and printing accuracy, precision and recall of the classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "pos_label=['Benign', 'Malignant']\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, pos_label= \"Malignant\"))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, pos_label= \"Malignant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dce1f2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123166</td>\n",
       "      <td>3.633732</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>1.411423</td>\n",
       "      <td>2.159395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529293</td>\n",
       "      <td>1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.028657</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>0.541452</td>\n",
       "      <td>-0.668173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232789</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960879</td>\n",
       "      <td>3.053423</td>\n",
       "      <td>1.429895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546748</td>\n",
       "      <td>-1.226494</td>\n",
       "      <td>-0.936206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459487</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074824</td>\n",
       "      <td>-2.375193</td>\n",
       "      <td>-0.596135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510723</td>\n",
       "      <td>-0.246709</td>\n",
       "      <td>-0.716338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809991</td>\n",
       "      <td>-0.534447</td>\n",
       "      <td>-0.192757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356031</td>\n",
       "      <td>-0.033741</td>\n",
       "      <td>0.567935</td>\n",
       "      <td>0.223103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184703</td>\n",
       "      <td>1.617836</td>\n",
       "      <td>1.698977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2         3         4         5         6\n",
       "0     9.192837   1.948583 -1.123166  3.633732 -1.195110  1.411423  2.159395\n",
       "1     2.387802  -3.768172 -0.529293  1.118264  0.621775  0.028657  0.013341\n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177086  0.541452 -0.668173\n",
       "3     7.122953  10.275589 -3.232789  0.152547 -2.960879  3.053423  1.429895\n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546748 -1.226494 -0.936206\n",
       "..         ...        ...       ...       ...       ...       ...       ...\n",
       "564   6.439315  -3.576817  2.459487  1.177314 -0.074824 -2.375193 -0.596135\n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510723 -0.246709 -0.716338\n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809991 -0.534447 -0.192757\n",
       "567  10.374794   1.672010 -1.877029 -2.356031 -0.033741  0.567935  0.223103\n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184703  1.617836  1.698977\n",
       "\n",
       "[569 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=7)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalComponents = pd.DataFrame(principalComponents)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5968d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the principal components as the input variables\n",
    "\n",
    "X = principalComponents.iloc[:, [0,1,2,3,4,5,6]].values\n",
    "Y = breast_dataset.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfb8fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "#splitting the dataset into 80% and 20% split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a1268ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing naive bays and building the classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34fc680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the classifier on the test data\n",
    "\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfb83d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9122807017543859\n",
      "Precision: 0.8873239436619719\n",
      "Recall: 0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "#importing and printing accuracy, precision and recall of the classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "pos_label=['Benign', 'Malignant']\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, pos_label= \"Malignant\"))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, pos_label= \"Malignant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6e473bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123166</td>\n",
       "      <td>3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>1.411424</td>\n",
       "      <td>2.159370</td>\n",
       "      <td>-0.398407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529293</td>\n",
       "      <td>1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.028657</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>0.240956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>0.541454</td>\n",
       "      <td>-0.668158</td>\n",
       "      <td>0.097252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232790</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960878</td>\n",
       "      <td>3.053423</td>\n",
       "      <td>1.429911</td>\n",
       "      <td>1.059540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546747</td>\n",
       "      <td>-1.226496</td>\n",
       "      <td>-0.936222</td>\n",
       "      <td>0.636503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459487</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074824</td>\n",
       "      <td>-2.375192</td>\n",
       "      <td>-0.596125</td>\n",
       "      <td>-0.035546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510722</td>\n",
       "      <td>-0.246710</td>\n",
       "      <td>-0.716323</td>\n",
       "      <td>-1.113402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809991</td>\n",
       "      <td>-0.534447</td>\n",
       "      <td>-0.192758</td>\n",
       "      <td>0.341881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356031</td>\n",
       "      <td>-0.033742</td>\n",
       "      <td>0.567936</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>-0.280169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184703</td>\n",
       "      <td>1.617837</td>\n",
       "      <td>1.698951</td>\n",
       "      <td>1.046357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2         3         4         5         6  \\\n",
       "0     9.192837   1.948583 -1.123166  3.633731 -1.195110  1.411424  2.159370   \n",
       "1     2.387802  -3.768172 -0.529293  1.118264  0.621775  0.028657  0.013360   \n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177086  0.541454 -0.668158   \n",
       "3     7.122953  10.275589 -3.232790  0.152547 -2.960878  3.053423  1.429911   \n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546747 -1.226496 -0.936222   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "564   6.439315  -3.576817  2.459487  1.177314 -0.074824 -2.375192 -0.596125   \n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510722 -0.246710 -0.716323   \n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809991 -0.534447 -0.192758   \n",
       "567  10.374794   1.672010 -1.877029 -2.356031 -0.033742  0.567936  0.223077   \n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184703  1.617837  1.698951   \n",
       "\n",
       "            7  \n",
       "0   -0.398407  \n",
       "1    0.240956  \n",
       "2    0.097252  \n",
       "3    1.059540  \n",
       "4    0.636503  \n",
       "..        ...  \n",
       "564 -0.035546  \n",
       "565 -1.113402  \n",
       "566  0.341881  \n",
       "567 -0.280169  \n",
       "568  1.046357  \n",
       "\n",
       "[569 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalComponents = pd.DataFrame(principalComponents)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db0d3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the principal components as the input variables\n",
    "\n",
    "X = principalComponents.iloc[:, [0,1,2,3,4,5,6,7]].values\n",
    "Y = breast_dataset.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5e86f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "#splitting the dataset into 80% and 20% split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8314c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing naive bays and building the classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6de6000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the classifier on the test data\n",
    "\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8306c766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9122807017543859\n",
      "Precision: 0.8873239436619719\n",
      "Recall: 0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "#importing and printing accuracy, precision and recall of the classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "pos_label=['Benign', 'Malignant']\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, pos_label= \"Malignant\"))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, pos_label= \"Malignant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf566d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123166</td>\n",
       "      <td>3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>1.411424</td>\n",
       "      <td>2.159369</td>\n",
       "      <td>-0.398329</td>\n",
       "      <td>-0.157154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529293</td>\n",
       "      <td>1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.028657</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.240946</td>\n",
       "      <td>-0.711883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>0.541452</td>\n",
       "      <td>-0.668167</td>\n",
       "      <td>0.097397</td>\n",
       "      <td>0.024060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232790</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960878</td>\n",
       "      <td>3.053422</td>\n",
       "      <td>1.429910</td>\n",
       "      <td>1.059550</td>\n",
       "      <td>-1.405426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546747</td>\n",
       "      <td>-1.226494</td>\n",
       "      <td>-0.936212</td>\n",
       "      <td>0.636353</td>\n",
       "      <td>-0.263799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459487</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074824</td>\n",
       "      <td>-2.375193</td>\n",
       "      <td>-0.596129</td>\n",
       "      <td>-0.035552</td>\n",
       "      <td>0.987963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510723</td>\n",
       "      <td>-0.246710</td>\n",
       "      <td>-0.716326</td>\n",
       "      <td>-1.113416</td>\n",
       "      <td>-0.105182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809991</td>\n",
       "      <td>-0.534447</td>\n",
       "      <td>-0.192758</td>\n",
       "      <td>0.341864</td>\n",
       "      <td>0.393931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356031</td>\n",
       "      <td>-0.033742</td>\n",
       "      <td>0.567936</td>\n",
       "      <td>0.223081</td>\n",
       "      <td>-0.280197</td>\n",
       "      <td>-0.542053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184703</td>\n",
       "      <td>1.617837</td>\n",
       "      <td>1.698950</td>\n",
       "      <td>1.046447</td>\n",
       "      <td>0.374064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2         3         4         5         6  \\\n",
       "0     9.192837   1.948583 -1.123166  3.633731 -1.195110  1.411424  2.159369   \n",
       "1     2.387802  -3.768172 -0.529293  1.118264  0.621775  0.028657  0.013359   \n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177086  0.541452 -0.668167   \n",
       "3     7.122953  10.275589 -3.232790  0.152547 -2.960878  3.053422  1.429910   \n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546747 -1.226494 -0.936212   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "564   6.439315  -3.576817  2.459487  1.177314 -0.074824 -2.375193 -0.596129   \n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510723 -0.246710 -0.716326   \n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809991 -0.534447 -0.192758   \n",
       "567  10.374794   1.672010 -1.877029 -2.356031 -0.033742  0.567936  0.223081   \n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184703  1.617837  1.698950   \n",
       "\n",
       "            7         8  \n",
       "0   -0.398329 -0.157154  \n",
       "1    0.240946 -0.711883  \n",
       "2    0.097397  0.024060  \n",
       "3    1.059550 -1.405426  \n",
       "4    0.636353 -0.263799  \n",
       "..        ...       ...  \n",
       "564 -0.035552  0.987963  \n",
       "565 -1.113416 -0.105182  \n",
       "566  0.341864  0.393931  \n",
       "567 -0.280197 -0.542053  \n",
       "568  1.046447  0.374064  \n",
       "\n",
       "[569 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=9)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalComponents = pd.DataFrame(principalComponents)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3abb69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the principal components as the input variables\n",
    "\n",
    "X = principalComponents.iloc[:, [0,1,2,3,4,5,6,7,8]].values\n",
    "Y = breast_dataset.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a8ad14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "#splitting the dataset into 80% and 20% split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cce8ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing naive bays and building the classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72f68aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the classifier on the test data\n",
    "\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e74475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9035087719298246\n",
      "Precision: 0.875\n",
      "Recall: 0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "#importing and printing accuracy, precision and recall of the classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "pos_label=['Benign', 'Malignant']\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, pos_label= \"Malignant\"))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, pos_label= \"Malignant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1edc1ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123166</td>\n",
       "      <td>3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>1.411424</td>\n",
       "      <td>2.159370</td>\n",
       "      <td>-0.398407</td>\n",
       "      <td>-0.157118</td>\n",
       "      <td>-0.877402</td>\n",
       "      <td>0.262955</td>\n",
       "      <td>-0.859014</td>\n",
       "      <td>0.103388</td>\n",
       "      <td>-0.690804</td>\n",
       "      <td>-0.601793</td>\n",
       "      <td>0.745116</td>\n",
       "      <td>-0.265471</td>\n",
       "      <td>-0.549563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529293</td>\n",
       "      <td>1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.240988</td>\n",
       "      <td>-0.711905</td>\n",
       "      <td>1.106995</td>\n",
       "      <td>0.813120</td>\n",
       "      <td>0.157923</td>\n",
       "      <td>-0.943529</td>\n",
       "      <td>-0.653475</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>-0.648809</td>\n",
       "      <td>-0.017212</td>\n",
       "      <td>0.318297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>0.541452</td>\n",
       "      <td>-0.668166</td>\n",
       "      <td>0.097374</td>\n",
       "      <td>0.024066</td>\n",
       "      <td>0.454275</td>\n",
       "      <td>-0.605604</td>\n",
       "      <td>0.124387</td>\n",
       "      <td>-0.410627</td>\n",
       "      <td>0.016680</td>\n",
       "      <td>0.483420</td>\n",
       "      <td>0.325111</td>\n",
       "      <td>0.190918</td>\n",
       "      <td>-0.087975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232790</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960878</td>\n",
       "      <td>3.053422</td>\n",
       "      <td>1.429911</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>-1.405440</td>\n",
       "      <td>-1.116975</td>\n",
       "      <td>-1.151514</td>\n",
       "      <td>1.011316</td>\n",
       "      <td>-0.933271</td>\n",
       "      <td>-0.487417</td>\n",
       "      <td>-0.168848</td>\n",
       "      <td>0.051370</td>\n",
       "      <td>0.482634</td>\n",
       "      <td>-0.035875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546747</td>\n",
       "      <td>-1.226495</td>\n",
       "      <td>-0.936213</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>-0.263805</td>\n",
       "      <td>0.377704</td>\n",
       "      <td>0.651360</td>\n",
       "      <td>-0.110515</td>\n",
       "      <td>0.387948</td>\n",
       "      <td>-0.539181</td>\n",
       "      <td>0.310319</td>\n",
       "      <td>-0.152606</td>\n",
       "      <td>0.133142</td>\n",
       "      <td>-0.018714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459487</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074824</td>\n",
       "      <td>-2.375193</td>\n",
       "      <td>-0.596130</td>\n",
       "      <td>-0.035471</td>\n",
       "      <td>0.987929</td>\n",
       "      <td>0.256989</td>\n",
       "      <td>-0.062651</td>\n",
       "      <td>0.123342</td>\n",
       "      <td>-0.051723</td>\n",
       "      <td>-0.404290</td>\n",
       "      <td>0.652750</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>0.348266</td>\n",
       "      <td>-0.195214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510723</td>\n",
       "      <td>-0.246710</td>\n",
       "      <td>-0.716326</td>\n",
       "      <td>-1.113360</td>\n",
       "      <td>-0.105207</td>\n",
       "      <td>-0.108632</td>\n",
       "      <td>0.244804</td>\n",
       "      <td>0.222753</td>\n",
       "      <td>-0.192637</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>-0.069975</td>\n",
       "      <td>-0.138184</td>\n",
       "      <td>0.293495</td>\n",
       "      <td>-0.109045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809991</td>\n",
       "      <td>-0.534447</td>\n",
       "      <td>-0.192758</td>\n",
       "      <td>0.341887</td>\n",
       "      <td>0.393917</td>\n",
       "      <td>0.520877</td>\n",
       "      <td>-0.840512</td>\n",
       "      <td>0.096473</td>\n",
       "      <td>0.157418</td>\n",
       "      <td>0.285691</td>\n",
       "      <td>0.090998</td>\n",
       "      <td>-0.232648</td>\n",
       "      <td>-0.065615</td>\n",
       "      <td>0.021108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356031</td>\n",
       "      <td>-0.033742</td>\n",
       "      <td>0.567936</td>\n",
       "      <td>0.223082</td>\n",
       "      <td>-0.280239</td>\n",
       "      <td>-0.542035</td>\n",
       "      <td>-0.089296</td>\n",
       "      <td>-0.178628</td>\n",
       "      <td>-0.697461</td>\n",
       "      <td>1.225195</td>\n",
       "      <td>0.218698</td>\n",
       "      <td>0.229591</td>\n",
       "      <td>-0.061047</td>\n",
       "      <td>-0.168514</td>\n",
       "      <td>-0.306874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184703</td>\n",
       "      <td>1.617837</td>\n",
       "      <td>1.698952</td>\n",
       "      <td>1.046354</td>\n",
       "      <td>0.374101</td>\n",
       "      <td>-0.047726</td>\n",
       "      <td>-0.144094</td>\n",
       "      <td>-0.179496</td>\n",
       "      <td>0.678897</td>\n",
       "      <td>-1.170725</td>\n",
       "      <td>0.217343</td>\n",
       "      <td>0.921288</td>\n",
       "      <td>-0.304810</td>\n",
       "      <td>-0.180972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1         2         3         4         5         6   \\\n",
       "0     9.192837   1.948583 -1.123166  3.633731 -1.195110  1.411424  2.159370   \n",
       "1     2.387802  -3.768172 -0.529293  1.118264  0.621775  0.028656  0.013358   \n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177086  0.541452 -0.668166   \n",
       "3     7.122953  10.275589 -3.232790  0.152547 -2.960878  3.053422  1.429911   \n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546747 -1.226495 -0.936213   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "564   6.439315  -3.576817  2.459487  1.177314 -0.074824 -2.375193 -0.596130   \n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510723 -0.246710 -0.716326   \n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809991 -0.534447 -0.192758   \n",
       "567  10.374794   1.672010 -1.877029 -2.356031 -0.033742  0.567936  0.223082   \n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184703  1.617837  1.698952   \n",
       "\n",
       "           7         8         9         10        11        12        13  \\\n",
       "0   -0.398407 -0.157118 -0.877402  0.262955 -0.859014  0.103388 -0.690804   \n",
       "1    0.240988 -0.711905  1.106995  0.813120  0.157923 -0.943529 -0.653475   \n",
       "2    0.097374  0.024066  0.454275 -0.605604  0.124387 -0.410627  0.016680   \n",
       "3    1.059565 -1.405440 -1.116975 -1.151514  1.011316 -0.933271 -0.487417   \n",
       "4    0.636376 -0.263805  0.377704  0.651360 -0.110515  0.387948 -0.539181   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "564 -0.035471  0.987929  0.256989 -0.062651  0.123342 -0.051723 -0.404290   \n",
       "565 -1.113360 -0.105207 -0.108632  0.244804  0.222753 -0.192637  0.015555   \n",
       "566  0.341887  0.393917  0.520877 -0.840512  0.096473  0.157418  0.285691   \n",
       "567 -0.280239 -0.542035 -0.089296 -0.178628 -0.697461  1.225195  0.218698   \n",
       "568  1.046354  0.374101 -0.047726 -0.144094 -0.179496  0.678897 -1.170725   \n",
       "\n",
       "           14        15        16        17  \n",
       "0   -0.601793  0.745116 -0.265471 -0.549563  \n",
       "1    0.008975 -0.648809 -0.017212  0.318297  \n",
       "2    0.483420  0.325111  0.190918 -0.087975  \n",
       "3   -0.168848  0.051370  0.482634 -0.035875  \n",
       "4    0.310319 -0.152606  0.133142 -0.018714  \n",
       "..        ...       ...       ...       ...  \n",
       "564  0.652750  0.147642  0.348266 -0.195214  \n",
       "565 -0.069975 -0.138184  0.293495 -0.109045  \n",
       "566  0.090998 -0.232648 -0.065615  0.021108  \n",
       "567  0.229591 -0.061047 -0.168514 -0.306874  \n",
       "568  0.217343  0.921288 -0.304810 -0.180972  \n",
       "\n",
       "[569 rows x 18 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=18)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalComponents = pd.DataFrame(principalComponents)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd3bc271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the principal components as the input variables\n",
    "\n",
    "X = principalComponents.iloc[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]].values\n",
    "Y = breast_dataset.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e6c2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "#splitting the dataset into 80% and 20% split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d98d995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing naive bays and building the classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96a25741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the classifier on the test data\n",
    "\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64bd7da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8947368421052632\n",
      "Precision: 0.863013698630137\n",
      "Recall: 0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "#importing and printing accuracy, precision and recall of the classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "pos_label=['Benign', 'Malignant']\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, pos_label= \"Malignant\"))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, pos_label= \"Malignant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0205fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123166</td>\n",
       "      <td>3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>1.411424</td>\n",
       "      <td>2.159370</td>\n",
       "      <td>-0.398407</td>\n",
       "      <td>-0.157118</td>\n",
       "      <td>-0.877402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745116</td>\n",
       "      <td>-0.265471</td>\n",
       "      <td>-0.549563</td>\n",
       "      <td>-0.133768</td>\n",
       "      <td>0.345565</td>\n",
       "      <td>0.096515</td>\n",
       "      <td>0.068850</td>\n",
       "      <td>0.084519</td>\n",
       "      <td>-0.175256</td>\n",
       "      <td>-0.151020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529293</td>\n",
       "      <td>1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.240988</td>\n",
       "      <td>-0.711905</td>\n",
       "      <td>1.106995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.648809</td>\n",
       "      <td>-0.017212</td>\n",
       "      <td>0.318297</td>\n",
       "      <td>0.247565</td>\n",
       "      <td>-0.114133</td>\n",
       "      <td>-0.077327</td>\n",
       "      <td>-0.094578</td>\n",
       "      <td>-0.217718</td>\n",
       "      <td>0.011290</td>\n",
       "      <td>-0.170510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>0.541452</td>\n",
       "      <td>-0.668166</td>\n",
       "      <td>0.097374</td>\n",
       "      <td>0.024066</td>\n",
       "      <td>0.454275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325111</td>\n",
       "      <td>0.190918</td>\n",
       "      <td>-0.087975</td>\n",
       "      <td>0.392626</td>\n",
       "      <td>-0.204532</td>\n",
       "      <td>0.311067</td>\n",
       "      <td>-0.060309</td>\n",
       "      <td>-0.074291</td>\n",
       "      <td>0.102762</td>\n",
       "      <td>0.171158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232790</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960878</td>\n",
       "      <td>3.053422</td>\n",
       "      <td>1.429911</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>-1.405440</td>\n",
       "      <td>-1.116975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051370</td>\n",
       "      <td>0.482634</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>0.026748</td>\n",
       "      <td>-0.464734</td>\n",
       "      <td>0.434193</td>\n",
       "      <td>-0.203266</td>\n",
       "      <td>-0.124105</td>\n",
       "      <td>0.153430</td>\n",
       "      <td>0.077496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546747</td>\n",
       "      <td>-1.226495</td>\n",
       "      <td>-0.936213</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>-0.263805</td>\n",
       "      <td>0.377704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152606</td>\n",
       "      <td>0.133142</td>\n",
       "      <td>-0.018714</td>\n",
       "      <td>-0.461436</td>\n",
       "      <td>0.065495</td>\n",
       "      <td>-0.116545</td>\n",
       "      <td>-0.017650</td>\n",
       "      <td>0.139454</td>\n",
       "      <td>-0.005332</td>\n",
       "      <td>0.003062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459487</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074824</td>\n",
       "      <td>-2.375193</td>\n",
       "      <td>-0.596130</td>\n",
       "      <td>-0.035471</td>\n",
       "      <td>0.987929</td>\n",
       "      <td>0.256989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>0.348266</td>\n",
       "      <td>-0.195214</td>\n",
       "      <td>0.246315</td>\n",
       "      <td>-0.404446</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>-0.067000</td>\n",
       "      <td>0.088590</td>\n",
       "      <td>0.107898</td>\n",
       "      <td>0.219520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510723</td>\n",
       "      <td>-0.246710</td>\n",
       "      <td>-0.716326</td>\n",
       "      <td>-1.113360</td>\n",
       "      <td>-0.105207</td>\n",
       "      <td>-0.108632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138184</td>\n",
       "      <td>0.293495</td>\n",
       "      <td>-0.109046</td>\n",
       "      <td>0.182521</td>\n",
       "      <td>-0.229947</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>0.019563</td>\n",
       "      <td>-0.055405</td>\n",
       "      <td>0.086135</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809991</td>\n",
       "      <td>-0.534447</td>\n",
       "      <td>-0.192758</td>\n",
       "      <td>0.341887</td>\n",
       "      <td>0.393917</td>\n",
       "      <td>0.520877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232648</td>\n",
       "      <td>-0.065615</td>\n",
       "      <td>0.021108</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>-0.081420</td>\n",
       "      <td>-0.036592</td>\n",
       "      <td>0.063352</td>\n",
       "      <td>-0.200312</td>\n",
       "      <td>-0.044819</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356031</td>\n",
       "      <td>-0.033742</td>\n",
       "      <td>0.567936</td>\n",
       "      <td>0.223082</td>\n",
       "      <td>-0.280239</td>\n",
       "      <td>-0.542035</td>\n",
       "      <td>-0.089296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061047</td>\n",
       "      <td>-0.168514</td>\n",
       "      <td>-0.306874</td>\n",
       "      <td>-0.310569</td>\n",
       "      <td>0.173216</td>\n",
       "      <td>0.140648</td>\n",
       "      <td>-0.042478</td>\n",
       "      <td>0.168820</td>\n",
       "      <td>-0.195969</td>\n",
       "      <td>0.377830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184703</td>\n",
       "      <td>1.617837</td>\n",
       "      <td>1.698952</td>\n",
       "      <td>1.046354</td>\n",
       "      <td>0.374101</td>\n",
       "      <td>-0.047726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921288</td>\n",
       "      <td>-0.304810</td>\n",
       "      <td>-0.180972</td>\n",
       "      <td>-0.189104</td>\n",
       "      <td>0.163254</td>\n",
       "      <td>0.274680</td>\n",
       "      <td>-0.243238</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>-0.075111</td>\n",
       "      <td>-0.017508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1         2         3         4         5         6   \\\n",
       "0     9.192837   1.948583 -1.123166  3.633731 -1.195110  1.411424  2.159370   \n",
       "1     2.387802  -3.768172 -0.529293  1.118264  0.621775  0.028656  0.013358   \n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177086  0.541452 -0.668166   \n",
       "3     7.122953  10.275589 -3.232790  0.152547 -2.960878  3.053422  1.429911   \n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546747 -1.226495 -0.936213   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "564   6.439315  -3.576817  2.459487  1.177314 -0.074824 -2.375193 -0.596130   \n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510723 -0.246710 -0.716326   \n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809991 -0.534447 -0.192758   \n",
       "567  10.374794   1.672010 -1.877029 -2.356031 -0.033742  0.567936  0.223082   \n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184703  1.617837  1.698952   \n",
       "\n",
       "           7         8         9   ...        15        16        17  \\\n",
       "0   -0.398407 -0.157118 -0.877402  ...  0.745116 -0.265471 -0.549563   \n",
       "1    0.240988 -0.711905  1.106995  ... -0.648809 -0.017212  0.318297   \n",
       "2    0.097374  0.024066  0.454275  ...  0.325111  0.190918 -0.087975   \n",
       "3    1.059565 -1.405440 -1.116975  ...  0.051370  0.482634 -0.035875   \n",
       "4    0.636376 -0.263805  0.377704  ... -0.152606  0.133142 -0.018714   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "564 -0.035471  0.987929  0.256989  ...  0.147642  0.348266 -0.195214   \n",
       "565 -1.113360 -0.105207 -0.108632  ... -0.138184  0.293495 -0.109046   \n",
       "566  0.341887  0.393917  0.520877  ... -0.232648 -0.065615  0.021108   \n",
       "567 -0.280239 -0.542035 -0.089296  ... -0.061047 -0.168514 -0.306874   \n",
       "568  1.046354  0.374101 -0.047726  ...  0.921288 -0.304810 -0.180972   \n",
       "\n",
       "           18        19        20        21        22        23        24  \n",
       "0   -0.133768  0.345565  0.096515  0.068850  0.084519 -0.175256 -0.151020  \n",
       "1    0.247565 -0.114133 -0.077327 -0.094578 -0.217718  0.011290 -0.170510  \n",
       "2    0.392626 -0.204532  0.311067 -0.060309 -0.074291  0.102762  0.171158  \n",
       "3    0.026748 -0.464734  0.434193 -0.203266 -0.124105  0.153430  0.077496  \n",
       "4   -0.461436  0.065495 -0.116545 -0.017650  0.139454 -0.005332  0.003062  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "564  0.246315 -0.404446  0.006888 -0.067000  0.088590  0.107898  0.219520  \n",
       "565  0.182521 -0.229947 -0.009802  0.019563 -0.055405  0.086135  0.001197  \n",
       "566  0.042020 -0.081420 -0.036592  0.063352 -0.200312 -0.044819  0.002429  \n",
       "567 -0.310569  0.173216  0.140648 -0.042478  0.168820 -0.195969  0.377830  \n",
       "568 -0.189104  0.163254  0.274680 -0.243238  0.037915 -0.075111 -0.017508  \n",
       "\n",
       "[569 rows x 25 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=25)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalComponents = pd.DataFrame(principalComponents)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab657785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the principal components as the input variables\n",
    "\n",
    "X = principalComponents.iloc[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]].values\n",
    "Y = breast_dataset.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce7c132a-d43b-4006-a689-c111b2ed1911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.19283683e+00,  1.94858307e+00, -1.12316616e+00, ...,\n",
       "         8.45185932e-02, -1.75256284e-01, -1.51020059e-01],\n",
       "       [ 2.38780180e+00, -3.76817174e+00, -5.29292687e-01, ...,\n",
       "        -2.17718064e-01,  1.12901180e-02, -1.70510254e-01],\n",
       "       [ 5.73389628e+00, -1.07517380e+00, -5.51747593e-01, ...,\n",
       "        -7.42911248e-02,  1.02761759e-01,  1.71158125e-01],\n",
       "       ...,\n",
       "       [ 1.25617928e+00, -1.90229671e+00,  5.62730526e-01, ...,\n",
       "        -2.00311926e-01, -4.48191456e-02,  2.42875704e-03],\n",
       "       [ 1.03747941e+01,  1.67201011e+00, -1.87702933e+00, ...,\n",
       "         1.68819962e-01, -1.95968973e-01,  3.77830448e-01],\n",
       "       [-5.47524330e+00, -6.70636791e-01,  1.49044308e+00, ...,\n",
       "         3.79145455e-02, -7.51108972e-02, -1.75080109e-02]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1a4829f-7dcc-47bb-8700-3d371ecf2ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2567ce09-41e9-4c2a-b875-b498c53ab55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "#splitting the dataset into 80% and 20% split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd37aa55-f8ee-424e-96ce-7a8c33c83fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing naive bays and building the classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe04be56-5d33-4591-9ddd-2be5928cc7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant'], dtype='<U9')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the classifier on the test data\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "Y_pred[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09c55652-260d-449c-9cad-2266749f27d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 10],\n",
       "       [ 5, 60]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing and creating confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5c5654d-86f1-4869-9670-18633ff1c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868421052631579\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "#importing and printing accuracy, precision and recall of the classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "pos_label=['Benign', 'Malignant']\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, pos_label= \"Malignant\"))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, pos_label= \"Malignant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b0833b6-b784-4a1d-9a48-0dca47c13f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 427.9555555555555, 'Predicted label')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the confusion matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "class_names=['Benign','Malignant'] # name of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"BuPu\" ,fmt='g', xticklabels=class_names,yticklabels=class_names, )\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216871f8-a10d-4388-a712-d8c4ff78b20f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
